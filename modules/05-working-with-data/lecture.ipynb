{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kVAdJhH-jZ9"
   },
   "source": [
    "# Working with data\n",
    "\n",
    "Overview of today's learning goals:\n",
    "\n",
    "  1. Introduce pandas\n",
    "  2. Load data files\n",
    "  3. Clean and process data\n",
    "  4. Select, filter, and slice data from a dataset\n",
    "  5. Descriptive stats: central tendency and dispersion\n",
    "  6. Merging and concatenating datasets\n",
    "  7. Grouping and summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3j0h96qm-jZ_"
   },
   "outputs": [],
   "source": [
    "!curl -s -o pyproject.toml https://raw.githubusercontent.com/gboeing/ppd430/refs/heads/main/pyproject.toml && uv pip install -q -r pyproject.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4KOHU6W-jaA"
   },
   "outputs": [],
   "source": [
    "# something new: import these packages to work with data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ahr679ER-jaB"
   },
   "source": [
    "## 1. Introducing pandas\n",
    "\n",
    "https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ColG-n1v-jaB"
   },
   "outputs": [],
   "source": [
    "# review: a python list is a built-in data type\n",
    "my_list = [8, 6, 4, 2]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EpVO7lI-jaC"
   },
   "outputs": [],
   "source": [
    "# a numpy array is like a list\n",
    "# but faster, more compact, and lots more features\n",
    "my_array = np.array(my_list)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzLUzFtK-jaC"
   },
   "source": [
    "pandas has two primary data structures we will work with: Series and DataFrames\n",
    "\n",
    "### 1a. pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oXKMxH1-jaD"
   },
   "outputs": [],
   "source": [
    "# a pandas series is based on a numpy array: it's fast, compact, and has more functionality\n",
    "# perhaps most notably, it has an index which allows you to work naturally with tabular data\n",
    "my_series = pd.Series(my_list)\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3dCOYOU-jaE"
   },
   "outputs": [],
   "source": [
    "# look at a list-representation of the index\n",
    "my_series.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yowoEWcT-jaF"
   },
   "outputs": [],
   "source": [
    "# look at the series' values themselves\n",
    "my_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxNmJHlG-jaG"
   },
   "outputs": [],
   "source": [
    "# what's the data type of the series' values?\n",
    "type(my_series.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Rlronrq-jaG"
   },
   "outputs": [],
   "source": [
    "# what's the data type of the individual values themselves?\n",
    "my_series.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Us-I7nG--jaH"
   },
   "source": [
    "### 1b. pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8v2jRax-jaH"
   },
   "outputs": [],
   "source": [
    "# a dict can contain multiple lists and label them\n",
    "my_dict = {\n",
    "    \"hh_income\": [75125, 22075, 31950, 115400],\n",
    "    \"home_value\": [525000, 275000, 395000, 985000],\n",
    "}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZV4CJh7q-jaI"
   },
   "outputs": [],
   "source": [
    "# a pandas dataframe can contain one or more columns\n",
    "# each column is a pandas series\n",
    "# each row is a pandas series\n",
    "# you can create a dataframe by passing in a list, array, series, or dict\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6nleH_G-jaI"
   },
   "outputs": [],
   "source": [
    "# the row labels in the index are accessed by the .index attribute of the DataFrame object\n",
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wr5Xdny1-jaJ"
   },
   "outputs": [],
   "source": [
    "# the column labels are accessed by the .columns attribute of the DataFrame object\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNmzRfp4-jaJ"
   },
   "outputs": [],
   "source": [
    "# the data values are accessed by the .values attribute of the DataFrame object\n",
    "# this is a numpy (two-dimensional) array\n",
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bad1VrN-jaK"
   },
   "source": [
    "## 2. Loading data\n",
    "\n",
    "In practice, you'll work with data by loading a dataset file into pandas. CSV is the most common format. But pandas can also ingest tab-separated data, JSON, and proprietary file formats like Excel .xlsx files, Stata, SAS, and SPSS.\n",
    "\n",
    "Below, notice what pandas's `read_csv` function does:\n",
    "\n",
    "1. recognize the header row and get its variable names\n",
    "1. read all the rows and construct a pandas DataFrame (an assembly of pandas Series rows and columns)\n",
    "1. construct a unique index, beginning with zero\n",
    "1. infer the data type of each variable (ie, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jB4WBWS-jaK"
   },
   "outputs": [],
   "source": [
    "# load a data file\n",
    "# note the relative filepath! where is this file located?\n",
    "# note the dtype argument! always specify that fips codes are strings, otherwise pandas guesses int\n",
    "filepath = \"https://raw.githubusercontent.com/gboeing/ppd430/main/data/census_tracts_data_la.csv\"\n",
    "df = pd.read_csv(filepath, dtype={\"GEOID10\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShD89kVA-jaK"
   },
   "outputs": [],
   "source": [
    "# dataframe shape as rows, columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40Whtqb5-jaL"
   },
   "outputs": [],
   "source": [
    "# or use len to just see the number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeXBe7dm-jaL"
   },
   "outputs": [],
   "source": [
    "# view the dataframe's \"head\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rwa2cR9-jaL"
   },
   "outputs": [],
   "source": [
    "# view the dataframe's \"tail\"\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Sgk-HOo-jaM"
   },
   "source": [
    "#### What are these data?\n",
    "\n",
    "I gathered them from the census bureau (2017 5-year tract-level ACS) for you, then gave them meaningful variable names. It's a set of socioeconomic variables across all LA County census tracts:\n",
    "\n",
    "|column|description|\n",
    "|------|-----------|\n",
    "|total_pop|Estimate!!SEX AND AGE!!Total population|\n",
    "|median_age|Estimate!!SEX AND AGE!!Total population!!Median age (years)|\n",
    "|pct_hispanic|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Hispanic or Latino (of any race)|\n",
    "|pct_white|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!White alone|\n",
    "|pct_black|Percent Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!Black or African American alone|\n",
    "|pct_asian|Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino!!Asian alone|\n",
    "|pct_male|Percent Estimate!!SEX AND AGE!!Total population!!Male|\n",
    "|pct_single_family_home|Percent Estimate!!UNITS IN STRUCTURE!!Total housing units!!1-unit detached|\n",
    "|med_home_value|Estimate!!VALUE!!Owner-occupied units!!Median (dollars)|\n",
    "|med_rooms_per_home|Estimate!!ROOMS!!Total housing units!!Median rooms|\n",
    "|pct_built_before_1940|Percent Estimate!!YEAR STRUCTURE BUILT!!Total housing units!!Built 1939 or earlier|\n",
    "|pct_renting|Percent Estimate!!HOUSING TENURE!!Occupied housing units!!Renter-occupied|\n",
    "|rental_vacancy_rate|Estimate!!HOUSING OCCUPANCY!!Total housing units!!Rental vacancy rate|\n",
    "|avg_renter_household_size|Estimate!!HOUSING TENURE!!Occupied housing units!!Average household size of renter-occupied unit|\n",
    "|med_gross_rent|Estimate!!GROSS RENT!!Occupied units paying rent!!Median (dollars)|\n",
    "|med_household_income|Estimate!!INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS)!!Total households!!Median household income (dollars)|\n",
    "|mean_commute_time|Estimate!!COMMUTING TO WORK!!Workers 16 years and over!!Mean travel time to work (minutes)|\n",
    "|pct_commute_drive_alone|Percent Estimate!!COMMUTING TO WORK!!Workers 16 years and over!!Car truck or van drove alone|\n",
    "|pct_below_poverty|Percent Estimate!!PERCENTAGE OF FAMILIES AND PEOPLE WHOSE INCOME IN THE PAST 12 MONTHS IS BELOW THE POVERTY LEVEL!!All people|\n",
    "|pct_college_grad_student|Percent Estimate!!SCHOOL ENROLLMENT!!Population 3 years and over enrolled in school!!College or graduate school|\n",
    "|pct_same_residence_year_ago|Percent Estimate!!RESIDENCE 1 YEAR AGO!!Population 1 year and over!!Same house|\n",
    "|pct_bachelors_degree|Percent Estimate!!EDUCATIONAL ATTAINMENT!!Population 25 years and over!!Percent bachelor's degree or higher|\n",
    "|pct_english_only|Percent Estimate!!LANGUAGE SPOKEN AT HOME!!Population 5 years and over!!English only|\n",
    "|pct_foreign_born|Percent Estimate!!PLACE OF BIRTH!!Total population!!Foreign born|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sREj1ANg-jaM"
   },
   "source": [
    "## 3. Clean and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7I8nvKdT-jaN"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yzgX4KR-jaN"
   },
   "outputs": [],
   "source": [
    "# data types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct4wYnwX-jaN"
   },
   "outputs": [],
   "source": [
    "# access a single column like df['col_name']\n",
    "df[\"med_gross_rent\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12P5S8FY-jaO"
   },
   "outputs": [],
   "source": [
    "# pandas uses numpy's nan to represent null (missing) values\n",
    "print(np.nan)\n",
    "print(type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCNmOwZX-jaO"
   },
   "outputs": [],
   "source": [
    "# convert rent from string -> float\n",
    "df[\"med_gross_rent\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ9DHGsR-jaO"
   },
   "source": [
    "Didn't work! We need to clean up the stray alphabetical characters to get a numerical value. You can do string operations on pandas Series to clean up their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APv18A7j-jaO"
   },
   "outputs": [],
   "source": [
    "# do a string replace and assign back to that column, then change type to float\n",
    "df[\"med_gross_rent\"] = df[\"med_gross_rent\"].str.replace(\" (USD)\", \"\", regex=False)\n",
    "df[\"med_gross_rent\"] = df[\"med_gross_rent\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAlzXzUW-jaP"
   },
   "outputs": [],
   "source": [
    "# now clean up the income column then convert it from string -> float\n",
    "# do a string replace and assign back to that column\n",
    "df[\"med_household_income\"] = df[\"med_household_income\"].str.replace(\"$\", \"\", regex=False)\n",
    "df[\"med_household_income\"] = df[\"med_household_income\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwa4EooK-jaP"
   },
   "outputs": [],
   "source": [
    "# convert rent from float -> int\n",
    "df[\"med_gross_rent\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TQhP2k0-jaQ"
   },
   "source": [
    "You cannot store null values as type `int`, only as type `float`. You have three basic options:\n",
    "\n",
    "  1. Keep the column as float to retain the nulls - they are often important!\n",
    "  2. Drop all the rows that contain nulls if we need non-null data for our analysis\n",
    "  3. Fill in all the nulls with another value if we know a reliable default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Vj9sPjv-jaQ"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6beMzUn-jaQ"
   },
   "outputs": [],
   "source": [
    "# drop rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df.dropna(subset=[\"med_gross_rent\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP70wLud-jaR"
   },
   "outputs": [],
   "source": [
    "# fill in rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df[\"med_gross_rent\"].fillna(value=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCUv1JFA-jaR"
   },
   "outputs": [],
   "source": [
    "# more string operations: slice state fips and county fips out of the tract fips string\n",
    "# assign them to new dataframe columns\n",
    "df[\"state\"] = df[\"GEOID10\"].str.slice(0, 2)\n",
    "df[\"county\"] = df[\"GEOID10\"].str.slice(2, 5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyFQ0aF4-jaR"
   },
   "outputs": [],
   "source": [
    "# dict that maps state fips code -> state name\n",
    "fips = {\"04\": \"Arizona\", \"06\": \"California\", \"41\": \"Oregon\"}\n",
    "\n",
    "# replace fips code with state name with the replace() method\n",
    "df[\"state\"] = df[\"state\"].replace(fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtIi2SFy-jaS"
   },
   "outputs": [],
   "source": [
    "# you can rename columns with the rename() method\n",
    "# remember to reassign to save the result\n",
    "df = df.rename(columns={\"state\": \"state_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmjQUB_c-jaS"
   },
   "outputs": [],
   "source": [
    "# you can drop columns you don't need with the drop() method\n",
    "# remember to reassign to save the result\n",
    "df = df.drop(columns=[\"county\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8UpMiwe-jaS"
   },
   "outputs": [],
   "source": [
    "# inspect the cleaned-up dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tgUvaBt-jaT"
   },
   "outputs": [],
   "source": [
    "# save it to disk as a \"clean\" copy\n",
    "# note the filepath\n",
    "filepath = \"/content/drive/My Drive/Colab Notebooks/census_tracts_data_la-clean.csv\"\n",
    "df.to_csv(filepath, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-0WG5vlYc6_"
   },
   "outputs": [],
   "source": [
    "# and you can read it back in\n",
    "pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0mBPqJM-jaT"
   },
   "source": [
    "## 4. Selecting and slicing data from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aexkWzzq-jaT"
   },
   "outputs": [],
   "source": [
    "# CHEAT SHEET OF COMMON TASKS\n",
    "# Operation                       Syntax           Result\n",
    "# ------------------------------------------------------------\n",
    "# Select column by name           df[col]          Series\n",
    "# Select columns by name          df[col_list]     DataFrame\n",
    "# Select row by label             df.loc[label]    Series\n",
    "# Select row by integer location  df.iloc[loc]     Series\n",
    "# Slice rows by label             df.loc[a:c]      DataFrame\n",
    "# Select rows by boolean vector   df[mask]         DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZsI4ycg-jaU"
   },
   "source": [
    "### 4a. Select DataFrame's column(s) by name\n",
    "\n",
    "We saw some of this a minute ago. Let's look in a bit more detail and break down what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56mBRB7w-jaU"
   },
   "outputs": [],
   "source": [
    "# select a single column by column name\n",
    "# this is a pandas series\n",
    "df[\"total_pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ljq24Nc-jaU"
   },
   "outputs": [],
   "source": [
    "# select multiple columns by a list of column names\n",
    "# this is a pandas dataframe that is a subset of the original\n",
    "df[[\"total_pop\", \"median_age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs3Qg_kI-jaV"
   },
   "outputs": [],
   "source": [
    "# create a new column by assigning df['new_col'] to some set of values\n",
    "# you can do math operations on any numeric columns\n",
    "df[\"monthly_income\"] = df[\"med_household_income\"] / 12\n",
    "df[\"rent_burden\"] = df[\"med_gross_rent\"] / df[\"monthly_income\"]\n",
    "\n",
    "# inspect the results\n",
    "df[[\"med_household_income\", \"monthly_income\", \"med_gross_rent\", \"rent_burden\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yENawNMA-jaV"
   },
   "source": [
    "### 4b. Select row(s) by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS8vCw7b-jaV"
   },
   "outputs": [],
   "source": [
    "# use .loc to select by row label\n",
    "# returns the row as a series whose index is the dataframe column names\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pqOimhE-jaW"
   },
   "outputs": [],
   "source": [
    "# use .loc to select single value by row label, column name\n",
    "df.loc[0, \"pct_below_poverty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTq0j3mr-jaW"
   },
   "outputs": [],
   "source": [
    "# slice of rows from label 5 to label 7, inclusive\n",
    "# this returns a pandas dataframe\n",
    "df.loc[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5yOxTVB-jaW"
   },
   "outputs": [],
   "source": [
    "# slice of rows from label 1 to label 3, inclusive\n",
    "# slice of columns from pct_hispanic to pct_asian, inclusive\n",
    "df.loc[1:3, \"pct_hispanic\":\"pct_asian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEeyjiMy-jaW"
   },
   "outputs": [],
   "source": [
    "# subset of rows from with labels in list\n",
    "# subset of columns with names in list\n",
    "df.loc[[1, 3], [\"pct_hispanic\", \"pct_asian\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaqIAoFy-jaX"
   },
   "outputs": [],
   "source": [
    "# you can use a column of unique identifiers as the index\n",
    "# fips codes uniquely identify each row (but verify!)\n",
    "df = df.set_index(\"GEOID10\")\n",
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkW92HG2-jaX"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm-MFPab-jaX"
   },
   "outputs": [],
   "source": [
    "# .loc works by label, not by position in the dataframe\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myokhRGV-jaX"
   },
   "outputs": [],
   "source": [
    "# the index now contains fips codes, so you have to use .loc accordingly to select by row label\n",
    "df.loc[\"06037137201\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdMG2ECQ-jaY"
   },
   "source": [
    "### 4c. Select by (integer) position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJpUft1w-jaY"
   },
   "outputs": [],
   "source": [
    "# get the row in the zero-th position in the dataframe\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luU_nDSE-jaY"
   },
   "outputs": [],
   "source": [
    "# you can slice as well\n",
    "# note, while .loc[] is inclusive, .iloc[] is not\n",
    "# get the rows from position 0 up to but not including position 3 (ie, rows 0, 1, and 2)\n",
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKZEN8AO-jaY"
   },
   "outputs": [],
   "source": [
    "# get the value from the row in position 3 and the column in position 2 (zero-indexed)\n",
    "df.iloc[3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32dfmqHw-jaZ"
   },
   "source": [
    "### 4d. Select/filter by value\n",
    "\n",
    "You can subset or filter a dataframe for based on the values in its rows/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znh51zrr-jaZ"
   },
   "outputs": [],
   "source": [
    "# filter the dataframe by rows with 30%+ rent burden\n",
    "df[df[\"rent_burden\"] > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFjBjwNc-jaZ"
   },
   "outputs": [],
   "source": [
    "# what exactly did that do? let's break it out.\n",
    "df[\"rent_burden\"] > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z8chW7E-jaa"
   },
   "outputs": [],
   "source": [
    "# essentially a true/false mask that filters by value\n",
    "mask = df[\"rent_burden\"] > 0.3\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCz5bNPZ-jaa"
   },
   "outputs": [],
   "source": [
    "# you can chain multiple conditions together\n",
    "# pandas logical operators are: | for or, & for and, ~ for not\n",
    "# these must be grouped by using parentheses due to order of operations\n",
    "# question: which tracts are both rent-burdened and majority-Black?\n",
    "mask = (df[\"rent_burden\"] > 0.3) & (df[\"pct_black\"] > 50)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQsXx_iY-jaa"
   },
   "outputs": [],
   "source": [
    "# which tracts are both rent-burdened and either majority-Black or majority-Hispanic?\n",
    "mask1 = df[\"rent_burden\"] > 0.3\n",
    "mask2 = df[\"pct_black\"] > 50\n",
    "mask3 = df[\"pct_hispanic\"] > 50\n",
    "mask = mask1 & (mask2 | mask3)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "958LWWu8-jaa"
   },
   "outputs": [],
   "source": [
    "# see the mask\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6jGc-3h-jaa"
   },
   "outputs": [],
   "source": [
    "# ~ means not... it essentially flips trues to falses and vice-versa\n",
    "~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyVLwydu-jab"
   },
   "outputs": [],
   "source": [
    "# which rows are in a state that begins with \"Cal\"?\n",
    "# all of them... because we're looking only at LA county\n",
    "mask = df[\"state_name\"].str.startswith(\"Cal\")\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqqqHCiV-jab"
   },
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new subset dataframe containing all the rows with median home values above $800,000 and percent-White above 60%\n",
    "# how many rows did you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GuA9b1o-jab"
   },
   "source": [
    "## 5. Descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB1_MIC1-jab"
   },
   "outputs": [],
   "source": [
    "# what share of majority-White tracts are rent burdened?\n",
    "mask1 = df[\"pct_white\"] > 50\n",
    "mask2 = mask1 & (df[\"rent_burden\"] > 0.3)\n",
    "len(df[mask2]) / len(df[mask1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "To5UOZjv-jac"
   },
   "outputs": [],
   "source": [
    "# what share of majority-Hispanic tracts are rent burdened?\n",
    "mask1 = df[\"pct_hispanic\"] > 50\n",
    "mask2 = mask1 & (df[\"rent_burden\"] > 0.3)\n",
    "len(df[mask2]) / len(df[mask1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd6MgqOi-jac"
   },
   "outputs": [],
   "source": [
    "# you can sort the dataframe by values in some column\n",
    "df.sort_values(\"pct_below_poverty\", ascending=False).dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqLTcx2X-jac"
   },
   "outputs": [],
   "source": [
    "# use the describe() method to pull basic descriptive stats for some column\n",
    "df[\"med_household_income\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NBNQvde-jac"
   },
   "source": [
    "#### Or if you need the value of a single stat, call it directly\n",
    "\n",
    "Key measures of central tendency: mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAFkhZuH-jad"
   },
   "outputs": [],
   "source": [
    "# the mean, or \"average\" value\n",
    "df[\"med_household_income\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qi4vGpFR-jad"
   },
   "outputs": [],
   "source": [
    "# the median, or \"typical\" (ie, 50th percentile) value\n",
    "df[\"med_household_income\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rofCmnSM-jad"
   },
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new subset dataframe containing rows with median household income above the (tract) average in LA county\n",
    "# what is the median median home value across this subset of tracts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbMIluQP-jad"
   },
   "source": [
    "Key measures of dispersion or variability: range, IQR, variance, standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSCx1Ip1-jae"
   },
   "outputs": [],
   "source": [
    "df[\"med_household_income\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l7cdHMg-jae"
   },
   "outputs": [],
   "source": [
    "# which tract has the lowest median household income?\n",
    "df[\"med_household_income\"].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsnfRcfT-jae"
   },
   "outputs": [],
   "source": [
    "df[\"med_household_income\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmIBUuME-jae"
   },
   "outputs": [],
   "source": [
    "# what is the 90th-percentile value?\n",
    "df[\"med_household_income\"].quantile(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deNogWdF-jaf"
   },
   "outputs": [],
   "source": [
    "# calculate the distribution's range\n",
    "df[\"med_household_income\"].max() - df[\"med_household_income\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H2-X-rB-jaf"
   },
   "outputs": [],
   "source": [
    "# calculate its IQR\n",
    "df[\"med_household_income\"].quantile(0.75) - df[\"med_household_income\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVGjX-zR-jaf"
   },
   "outputs": [],
   "source": [
    "# calculate its variance... rarely used in practice\n",
    "df[\"med_household_income\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xu11e1Jj-jaf"
   },
   "outputs": [],
   "source": [
    "# calculate its standard deviation\n",
    "# this is the sqrt of the variance... putting it into same units as the variable itself\n",
    "df[\"med_household_income\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWc4Copc-jag"
   },
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# what's the average (mean) median home value across majority-White tracts? And across majority-Black tracts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q0nRKsA-jag"
   },
   "source": [
    "## 6. Merge and concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVnrPk7D-jag"
   },
   "source": [
    "### 6a. Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5smHHm6-jag"
   },
   "outputs": [],
   "source": [
    "# create a subset dataframe with only race/ethnicity variables\n",
    "race_cols = [\"pct_asian\", \"pct_black\", \"pct_hispanic\", \"pct_white\"]\n",
    "df_race = df[race_cols]\n",
    "df_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1PFhDwY-jah"
   },
   "outputs": [],
   "source": [
    "# create a subset dataframe with only economic variables\n",
    "econ_cols = [\"med_home_value\", \"med_household_income\"]\n",
    "df_econ = df[econ_cols].sort_values(\"med_household_income\")\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JWPJkhE-jah"
   },
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how=\"inner\", left_index=True, right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glxyhUA2-jah"
   },
   "outputs": [],
   "source": [
    "# reset df_econ's index\n",
    "df_econ = df_econ.reset_index()\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fG6I61uF-jai"
   },
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "# doesn't work! their indexes do not share any labels to match/align the rows\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how=\"inner\", left_index=True, right_index=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9wfLPEZ-jai"
   },
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# change the \"how\" argument: what happens if you try an \"outer\" join? or a \"left\" join? or a \"right\" join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmIOhANF-jai"
   },
   "outputs": [],
   "source": [
    "# instead merge where df_race index matches df_econ GEOID10 column\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how=\"inner\", left_on=\"GEOID10\", right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8tNqaTs-jai"
   },
   "source": [
    "### 6b. Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnFSwf-o-jai"
   },
   "outputs": [],
   "source": [
    "# load the orange county tracts data\n",
    "filepath = \"https://raw.githubusercontent.com/gboeing/ppd430/main/data/census_tracts_data_oc.csv\"\n",
    "oc = pd.read_csv(filepath, dtype={\"GEOID10\": str})\n",
    "oc = oc.set_index(\"GEOID10\")\n",
    "oc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAOubcwM-jai"
   },
   "outputs": [],
   "source": [
    "oc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXiD1AXc-jai"
   },
   "outputs": [],
   "source": [
    "# merging joins data together aligned by the index, but concatenating just smushes it together along some axis\n",
    "df_all = pd.concat([df, oc], sort=False)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrHounzo-jaj"
   },
   "source": [
    "## 7. Grouping and summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD0nwL1y-jaj"
   },
   "outputs": [],
   "source": [
    "# extract county fips from index then replace with friendly name\n",
    "df_all[\"county\"] = df_all.index.str.slice(2, 5)\n",
    "df_all[\"county\"] = df_all[\"county\"].replace({\"037\": \"LA\", \"059\": \"OC\"})\n",
    "df_all[\"county\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4rr_k80-jaj"
   },
   "outputs": [],
   "source": [
    "# group the rows by county\n",
    "counties = df_all.groupby(\"county\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfh3ImM7-jaj"
   },
   "outputs": [],
   "source": [
    "# what is the median pct_white across the tracts in each county?\n",
    "counties[\"pct_white\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dczLlzLL-jaj"
   },
   "outputs": [],
   "source": [
    "# look at several columns' medians by county\n",
    "counties[[\"pct_bachelors_degree\", \"pct_foreign_born\", \"pct_commute_drive_alone\"]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vwo0Oq1-jaj"
   },
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# group the tracts by county and find the highest/lowest tract percentages that speak English-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvukyfGx-jaj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
